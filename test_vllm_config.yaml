data:
  train_files: hiyouga/math12k@train
  val_files: hiyouga/math12k@test
  prompt_key: problem
  answer_key: answer
  image_key: images
  max_prompt_length: 2048
  max_response_length: 2048
  rollout_batch_size: 512
  val_batch_size: -1
  shuffle: true
  seed: 1

worker:
  actor:
    model:
      model_path: Qwen/Qwen2.5-7B-Instruct
      trust_remote_code: false

  reward:
    # Use vLLM for reward calculation
    compute_score: "openr1_vllm"
    batch_processing: true
    provider: "vllm"  
    base_url: "http://localhost:8000/v1"  # URL of your vLLM server
    model_name: "Qwen2.5-1.5B-Instruct"   # Model name served by vLLM
    api_key: "dummy-key-for-vllm"         # API key (can be dummy for vLLM)
    cos_len_reward_config:
      min_value_wrong: -1.0
      max_value_wrong: -0.5
      min_value_correct: 0.0
      max_value_correct: 0.0

trainer:
  total_episodes: 1  # Just for testing
  n_gpus_per_node: 1
  nnodes: 1
  val_freq: 1
  val_before_train: true
  val_only: true  # Only run validation for testing 